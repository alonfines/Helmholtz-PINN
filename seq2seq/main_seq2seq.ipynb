{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNt7nbqHfgFphqeeXdWnqes"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"007mq7CltaRM","executionInfo":{"status":"ok","timestamp":1740919681695,"user_tz":-120,"elapsed":2165,"user":{"displayName":"Alon Finestein","userId":"16445456418810970498"}},"outputId":"b7a368f2-d87c-4786-eece-3b721be1e77a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/MSc/Year 1/Semester A/למידה עמוקה לבעיות פיזיקאליות 361.2.2330/Project/curriculum')"]},{"cell_type":"code","source":["!pip install pytorch-lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbPJmAdQtuxe","executionInfo":{"status":"ok","timestamp":1740916849018,"user_tz":-120,"elapsed":108717,"user":{"displayName":"Alon Finestein","userId":"16445456418810970498"}},"outputId":"1d91b637-c505-489c-9448-423fb2953ff3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.5.1+cu124)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.10.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.12.2)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.13)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.5)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n","Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed lightning-utilities-0.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.0.post0 torchmetrics-1.6.1\n"]}]},{"cell_type":"code","source":["!python train_curriculum.py --k_squared 3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QwZRidcux7r","executionInfo":{"status":"ok","timestamp":1740919902413,"user_tz":-120,"elapsed":15134,"user":{"displayName":"Alon Finestein","userId":"16445456418810970498"}},"outputId":"f70dcf0f-a998-4faa-87d5-4e8e5c77dd26"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.\n","GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n","\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n","/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /content/drive/MyDrive/MSc/Year 1/Semester A/למידה עמוקה לבעיות פיזיקאליות 361.2.2330/Project/curriculum/checkpoints exists and is not empty.\n","\n","  | Name  | Type       | Params | Mode \n","---------------------------------------------\n","0 | model | Sequential | 5.3 K  | train\n","---------------------------------------------\n","5.3 K     Trainable params\n","0         Non-trainable params\n","5.3 K     Total params\n","0.021     Total estimated model params size (MB)\n","8         Modules in train mode\n","0         Modules in eval mode\n","/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Epoch 0: 100% 10/10 [00:02<00:00,  4.50it/s, v_num=sm12, watch_loss=0.247, train_loss=0.0694, pde_loss=0.179, bc_loss=0.0682, lambda1=0.011, lambda2=0.989]Metric watch_loss improved. New best score: 0.247\n","Epoch 1: 100% 10/10 [00:01<00:00,  5.16it/s, v_num=sm12, watch_loss=0.0749, train_loss=0.0617, pde_loss=0.0127, bc_loss=0.0622, lambda1=0.011, lambda2=0.989]Metric watch_loss improved by 0.172 >= min_delta = 0.0. New best score: 0.075\n","Epoch 2:  20% 2/10 [00:00<00:01,  4.72it/s, v_num=sm12, watch_loss=0.0758, train_loss=0.0589, pde_loss=0.0164, bc_loss=0.0594, lambda1=0.011, lambda2=0.989]\n","Detected KeyboardInterrupt, attempting graceful shutdown ...\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n","    return trainer_fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 575, in _fit_impl\n","    self._run(model, ckpt_path=ckpt_path)\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 982, in _run\n","    results = self._run_stage()\n","              ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n","    self.fit_loop.run()\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n","    self.advance()\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n","    self.epoch_loop.run(self._data_fetcher)\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 150, in run\n","    self.advance(data_fetcher)\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 339, in advance\n","    call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\", line 222, in _call_callback_hooks\n","    fn(trainer, trainer.lightning_module, *args, **kwargs)\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 278, in on_train_batch_end\n","    _update_n(self.train_progress_bar, n)\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 459, in _update_n\n","    bar.refresh()\n","  File \"/usr/local/lib/python3.11/dist-packages/tqdm/std.py\", line 1347, in refresh\n","    self.display()\n","  File \"/usr/local/lib/python3.11/dist-packages/tqdm/std.py\", line 1495, in display\n","    self.sp(self.__str__() if msg is None else msg)\n","            ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/tqdm/std.py\", line 1151, in __str__\n","    return self.format_meter(**self.format_dict)\n","                               ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/tqdm/std.py\", line 1453, in format_dict\n","    self.ncols, self.nrows = self.dynamic_ncols(self.fp)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/tqdm/utils.py\", line 343, in _screen_shape_linux\n","    rows, cols = array('h', ioctl(fp, TIOCGWINSZ, '\\0' * 8))[:2]\n","                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MSc/Year 1/Semester A/למידה עמוקה לבעיות פיזיקאליות 361.2.2330/Project/curriculum/train_curriculum.py\", line 110, in <module>\n","    trainer.fit(model, train_loader)\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 539, in fit\n","    call._call_and_handle_interrupt(\n","  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\", line 56, in _call_and_handle_interrupt\n","    rank_zero_info(\"\\nDetected KeyboardInterrupt, attempting graceful shutdown ...\")\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/rank_zero.py\", line 42, in wrapped_fn\n","    return fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/rank_zero.py\", line 69, in rank_zero_info\n","    _info(*args, stacklevel=stacklevel, **kwargs)\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/rank_zero.py\", line 63, in _info\n","    log.info(*args, **kwargs)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1489, in info\n","    self._log(INFO, msg, args, **kwargs)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n","    self.emit(record)\n","  File \"/usr/lib/python3.11/logging/__init__.py\", line 1113, in emit\n","    stream.write(msg + self.terminator)\n","  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/redirect.py\", line 648, in write\n","    cb(data)\n","  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 2302, in <lambda>\n","    lambda data: self._console_raw_callback(\"stderr\", data),\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 401, in wrapper_fn\n","    return func(self, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_run.py\", line 1444, in _console_raw_callback\n","    self._backend.interface.publish_output_raw(name, data)\n","  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface.py\", line 763, in publish_output_raw\n","    self._publish_output_raw(o)\n","  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/interface/interface_shared.py\", line 45, in _publish_output_raw\n","    def _publish_output_raw(self, outdata: pb.OutputRawRecord) -> None:\n","    \n","KeyboardInterrupt\n","\u001b[1;34mwandb\u001b[0m: \n","\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/MSc/Year 1/Semester A/למידה עמוקה לבעיות פיזיקאליות 361.2.2330/Project/curriculum/wandb/offline-run-20250302_125135-qp12sm12\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250302_125135-qp12sm12/logs\u001b[0m\n","^C\n"]}]}]}